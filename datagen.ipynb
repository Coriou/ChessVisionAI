{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 12 pieces in our original dataset: 6 for each color as well as two empty squares.\n",
    "\n",
    "This notebook creates a bunch of variations for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import (  # type: ignore\n",
    "    ImageDataGenerator,\n",
    "    img_to_array,\n",
    "    array_to_img\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "The `dataset` directory will be created from the code below, including the background squares (using only a dark and light square as background seem to be enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data/pieces\"\n",
    "empty_board = \"data/empty_board.png\"\n",
    "backgrounds = [\"dataset/squares/square_0_1.png\", \"dataset/squares/square_0_2.png\"]\n",
    "training_data_dir = \"dataset/training\"\n",
    "test_data_dir = \"dataset/test\"\n",
    "squares_dir = \"dataset/squares\"\n",
    "num_images = 10_000 # Images to generate / piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(training_data_dir, exist_ok=True)\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "os.makedirs(squares_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create empty squares from empty board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty squares have been generated and saved. Total squares: 64\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "board_image = Image.open(empty_board)\n",
    "\n",
    "# Get the size of the board\n",
    "board_width, board_height = board_image.size\n",
    "if board_width != board_height:\n",
    "    raise ValueError(\"The board image is not square!\")\n",
    "\n",
    "square_size = board_width // 8\n",
    "\n",
    "# Loop to crop and save each square\n",
    "count = 0\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        left = col * square_size\n",
    "        top = row * square_size\n",
    "        right = left + square_size\n",
    "        bottom = top + square_size\n",
    "\n",
    "        square_image = board_image.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the square image\n",
    "        square_name = f\"square_{row}_{col}.png\"\n",
    "        square_image.save(os.path.join(squares_dir, square_name))\n",
    "        count += 1\n",
    "\n",
    "# Should always be 64\n",
    "print(f\"Empty squares have been generated and saved. Total squares: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation generator for the pieces\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "# Define augmentation generator for the empty squares\n",
    "# same as above but basically divided ranges by two.\n",
    "# Not sure it's a good iea, needs testing\n",
    "datagen_empty = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode=\"nearest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay image on background\n",
    "def add_background(piece_path, background_paths, num_images_per_bg):\n",
    "    piece = Image.open(piece_path).convert(\"RGBA\")\n",
    "    images = []\n",
    "    for bg_path in background_paths:\n",
    "        background = Image.open(bg_path).convert(\"RGBA\")\n",
    "        background = background.resize(piece.size, Image.Resampling.LANCZOS)\n",
    "        for _ in range(num_images_per_bg):\n",
    "            combined = Image.alpha_composite(background, piece)\n",
    "            images.append(combined)\n",
    "    return images\n",
    "\n",
    "\n",
    "# Generate and save augmented images for the pieces\n",
    "def augment_and_save(images, output_path, num_augmented=50):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for img in images:\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(\n",
    "            x,\n",
    "            batch_size=1,\n",
    "            save_to_dir=None,\n",
    "            save_format=\"png\",\n",
    "        ):\n",
    "            augmented_img = batch[0]\n",
    "            img = array_to_img(augmented_img, scale=True)\n",
    "            unique_id = uuid.uuid4().hex\n",
    "            filename = f\"augmented_{unique_id}.png\"\n",
    "            img.save(os.path.join(output_path, filename))\n",
    "            i += 1\n",
    "            if i >= num_augmented // len(images):\n",
    "                break\n",
    "\n",
    "\n",
    "# Check if an image is valid and non-empty\n",
    "def is_valid_image(img):\n",
    "    if img is None:\n",
    "        return False\n",
    "    if img.size == (0, 0):\n",
    "        return False\n",
    "    if np.array(img).mean() == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Augment and save empty squares separately, ensuring unique types are included\n",
    "def augment_empty_square(img, num_augmented):\n",
    "    augmented_images = []\n",
    "    x = img_to_array(img)\n",
    "    if x.size == 0:\n",
    "        print(f\"Skipping invalid image with shape: {img.size}\")\n",
    "        return []\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    for batch in datagen_empty.flow(\n",
    "        x,\n",
    "        batch_size=1,\n",
    "        save_to_dir=None,\n",
    "        save_format=\"png\",\n",
    "    ):\n",
    "        augmented_img = batch[0]\n",
    "        if np.array(augmented_img).mean() == 0:\n",
    "            print(\"Skipping generated empty image\")\n",
    "            continue\n",
    "        augmented_images.append(augmented_img)\n",
    "        if len(augmented_images) >= num_augmented:\n",
    "            break\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "def load_and_classify_empty_squares(empty_square_dir):\n",
    "    unique_squares = {\n",
    "        \"left_hedge\": [],\n",
    "        \"bottom_hedge\": [],\n",
    "        \"dark_square\": None,\n",
    "        \"light_square\": None,\n",
    "    }\n",
    "\n",
    "    for filename in os.listdir(empty_square_dir):\n",
    "        piece_path = os.path.join(empty_square_dir, filename)\n",
    "        try:\n",
    "            empty_image = Image.open(piece_path).convert(\"RGBA\")\n",
    "            if not is_valid_image(empty_image):\n",
    "                print(f\"Invalid image: {piece_path}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {piece_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        _, row, col = filename.rstrip(\".png\").split(\"_\")\n",
    "        row, col = int(row), int(col)\n",
    "\n",
    "        if col == 0:\n",
    "            unique_squares[\"left_hedge\"].append(empty_image)\n",
    "        elif row == 7:\n",
    "            unique_squares[\"bottom_hedge\"].append(empty_image)\n",
    "        elif (\n",
    "            unique_squares[\"dark_square\"] is None and np.array(empty_image).mean() < 127\n",
    "        ):\n",
    "            unique_squares[\"dark_square\"] = empty_image\n",
    "        elif (\n",
    "            unique_squares[\"light_square\"] is None\n",
    "            and np.array(empty_image).mean() >= 127\n",
    "        ):\n",
    "            unique_squares[\"light_square\"] = empty_image\n",
    "\n",
    "    return (\n",
    "        unique_squares[\"left_hedge\"]\n",
    "        + unique_squares[\"bottom_hedge\"]\n",
    "        + [unique_squares[\"dark_square\"], unique_squares[\"light_square\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def process_empty_squares(\n",
    "    unique_images, output_train_dir, output_test_dir, num_augmented\n",
    "):\n",
    "    all_augmented_images = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(augment_empty_square, img, num_augmented)\n",
    "            for img in unique_images\n",
    "        ]\n",
    "        for future in futures:\n",
    "            all_augmented_images.extend(future.result())\n",
    "\n",
    "    # Split between training and test\n",
    "    random.shuffle(all_augmented_images)\n",
    "    split_index = int(len(all_augmented_images) * 0.8)\n",
    "    train_images = all_augmented_images[:split_index]\n",
    "    test_images = all_augmented_images[split_index:]\n",
    "\n",
    "    # Save augmented empty squares to training set\n",
    "    os.makedirs(output_train_dir, exist_ok=True)\n",
    "    for img in train_images:\n",
    "        img = array_to_img(img, scale=True)\n",
    "        unique_id = uuid.uuid4().hex\n",
    "        filename = f\"augmented_{unique_id}.png\"\n",
    "        img.save(os.path.join(output_train_dir, filename))\n",
    "\n",
    "    # Save augmented empty squares to test set\n",
    "    os.makedirs(output_test_dir, exist_ok=True)\n",
    "    for img in test_images:\n",
    "        img = array_to_img(img, scale=True)\n",
    "        unique_id = uuid.uuid4().hex\n",
    "        filename = f\"augmented_{unique_id}.png\"\n",
    "        img.save(os.path.join(output_test_dir, filename))\n",
    "\n",
    "\n",
    "def process_piece(\n",
    "    color, filename, backgrounds, num_images, training_data_dir, test_data_dir\n",
    "):\n",
    "    piece_type = filename.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    # Add background and augment\n",
    "    piece_path = os.path.join(base_dir, color, filename)\n",
    "    images = add_background(piece_path, backgrounds, num_images)\n",
    "\n",
    "    # Split between training and test\n",
    "    random.shuffle(images)\n",
    "    split_index = int(len(images) * 0.8)\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Save augmented images to training set\n",
    "    output_piece_train_dir = os.path.join(training_data_dir, f\"{color[0]}_{piece_type}\")\n",
    "    os.makedirs(output_piece_train_dir, exist_ok=True)\n",
    "    augment_and_save(train_images, output_piece_train_dir)\n",
    "\n",
    "    # Save augmented images to test set\n",
    "    output_piece_test_dir = os.path.join(test_data_dir, f\"{color[0]}_{piece_type}\")\n",
    "    os.makedirs(output_piece_test_dir, exist_ok=True)\n",
    "    augment_and_save(test_images, output_piece_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating pieces dataset\n"
     ]
    }
   ],
   "source": [
    "# Augment and save pieces\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for color in [\"black\", \"white\"]:\n",
    "        color_dir = os.path.join(base_dir, color)\n",
    "        for filename in os.listdir(color_dir):\n",
    "            futures.append(\n",
    "                executor.submit(\n",
    "                    process_piece,\n",
    "                    color,\n",
    "                    filename,\n",
    "                    backgrounds,\n",
    "                    num_images,\n",
    "                    training_data_dir,\n",
    "                    test_data_dir,\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(\"Done generating pieces dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating empty squares dataset\n"
     ]
    }
   ],
   "source": [
    "# Augment and save empty squares\n",
    "unique_images = load_and_classify_empty_squares(squares_dir)\n",
    "unique_images = [img for img in unique_images if img is not None]\n",
    "\n",
    "process_empty_squares(\n",
    "    unique_images,\n",
    "    os.path.join(training_data_dir, \"empty\"),\n",
    "    os.path.join(test_data_dir, \"empty\"),\n",
    "    round(num_images / 15),\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Done generating empty squares dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
